---
title: "Logistic Regression"
author: "Fu Yunxiang"
date: "2021/12/3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
setwd("C:\\Users\\user\\Documents\\HKU\\Y3 s1\\STAT3612 Statistical Machine Learning\\Project")
IncomeData = read.csv("clean.csv")
IncomeData[sapply(IncomeData, is.character)] <- lapply(IncomeData[sapply(IncomeData, is.character)], as.factor)
head(IncomeData)
```


```{r}
set.seed(12L)
library(caret)
mycontrol <- trainControl(summaryFunction = twoClassSummary, method="cv", number=10, classProbs = TRUE)
```


```{r}
```


Logistic Regression:
```{r}
#train model
logistic_mod = train(income ~.,
  data = IncomeData,
  trControl = mycontrol,
  metric="ROC",
  #preProcess = c("center", "scale"),
  method = "glm"
)
print(logistic_mod)
```

```{r}
summary(logistic_mod)
```

Show all variables 
```{r}
names(IncomeData)
```
Remove each variable and perform ANOVA test. The result is that all variables are significant so we should keep them.
```{r}
logistic_mod2 = train(income ~. -education.num,
  data = IncomeData,
  trControl = mycontrol,
  metric="ROC",
  #preProcess = c("center", "scale"),
  method = "glm"
)
```

#From the anova results, we conclude that all variables are significant.
```{r}
anova(logistic_mod$finalModel, logistic_mod2$finalModel, test = "Chisq")
```

#Now we check assumptions and large residuals

Check assumptions by plots below:
```{r}
LogitModel = logistic_mod$finalModel
plot(LogitModel)
```

Check large residuals:

We first observe patterns for the 15 largest residuals
```{r}
r <- residuals(LogitModel)
temp = abs(r)
temp = order(temp,decreasing = TRUE)
IncomeData[temp[1:15],]
```
Observe that white US males that earn >50K and have 0 net.capital.gain, with marital.status = "not-married" or "other" appears frequently.




Federal.gov is used as baseline
```{r}
levels(IncomeData$workclass)
```
Adm.clerical is used as baseline
```{r}
levels(IncomeData$occupation)
```
Amer-Indian-Eskimo is used as baseline
```{r}
levels(IncomeData$race)
```

```{r}
levels(IncomeData$workclass) = c("Government","Government","Private","Self.emp","Self.emp","Government","Without.pay")
```

```{r}
levels(IncomeData$race) = c("Other", "Other", "Black", "Other", "white")
```

```{r}
levels()
```

```{r}
logistic_mod3 = train(income ~.^2,
  data = IncomeData,
  trControl = mycontrol,
  metric="ROC",
  method = "glm"
)
print(logistic_mod3)
```


Note adding second order terms does not improve accuracy much.
```{r}
mycontrol <- trainControl(summaryFunction = twoClassSummary, method="cv", number=10, classProbs = TRUE, savePredictions = TRUE)
#train model
logistic_mod2 = train(income ~.^2,
  data = IncomeData,
  trControl = mycontrol,
  metric="ROC",
  method = "glm"
)
print(logistic_mod2)
```

```{r}
pred = predict(logistic_mod)
pred2 = predict(logistic_mod2$pred)
confusionMatrix(pred,IncomeData$income)
confusionMatrix(pred2,IncomeData$income)
```
